# API Data Lake 1

Ce projet est une API sÃ©curisÃ©e et traÃ§able permettant d'exposer des donnÃ©es issues dâ€™un data lake simulÃ©.
Il a Ã©tÃ© rÃ©alisÃ© avec Django REST Framework, JWT pour la sÃ©curitÃ©, SQLite pour le stockage local, et Streamlit pour lâ€™interface de test interactive.

---

## Installation

### 1. Cloner le projet
```bash
git clone <url_du_repo>
cd data_lake_api
```

### 2. CrÃ©er et activer l'environnement virtuel
```bash
python -m venv venv
venv\Scripts\activate     # Windows
source venv/bin/activate  # Linux/macOS
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

---

## Lancer lâ€™API Django

```bash
python manage.py migrate
python manage.py createsuperuser  # si nÃ©cessaire
python manage.py runserver
```

---

## AccÃ¨s Ã  l'API

| Composant              | URL                                    |
|------------------------|-----------------------------------------|
| Swagger (doc auto)     | http://127.0.0.1:8000/swagger/          |
| Interface Streamlit    | http://localhost:8501                   |
| Admin Django           | http://127.0.0.1:8000/admin/            |

---

## Lancer lâ€™interface Streamlit

```bash
streamlit run app.py
```

FonctionnalitÃ©s de lâ€™app :
- ğŸ” Connexion via JWT
- ğŸ“‚ AperÃ§u et export du dataset
- ğŸ“„ RequÃªtes paramÃ©trables (filtres, projections)
- ğŸ“Š MÃ©triques analytiques
- ğŸ” Recherche full-text
- ğŸ§¾ Audit et lineage
- ğŸ” Simulation repush Kafka
- ğŸ§  DÃ©clenchement d'un modÃ¨le ML simulÃ©

---

## Importer les donnÃ©es (dataset CSV enrichi)

```bash
python manage.py import_transactions
```

Le fichier utilisÃ© se trouve dans `bronze/global_superstore_enriched.csv`

---

## Authentification (JWT)

- Endpoint : `/api/token/`
- Utiliser le token pour accÃ©der aux routes sÃ©curisÃ©es
- Streamlit gÃ¨re cette connexion automatiquement

---

## Endpoints disponibles (rÃ©sumÃ©)

- `GET /api/transactions/`
- `GET /api/metrics/<nom_metric>/`
- `GET /api/search/?q=...`
- `GET /api/audit/`
- `GET /api/lineage/<id>/`
- `POST /api/repush/<id>/`
- `POST /api/train-ml/`

---

## FonctionnalitÃ©s avancÃ©es

- ğŸ” **Search** : recherche multi-champs
- ğŸ“Š **MÃ©triques** : dÃ©pense moyenne, top produits, CA par pays, etc.
- ğŸ§¾ **Audit & Lineage** : suivi des accÃ¨s et journalisation
- ğŸ§  **ML Simulation** : fonction de machine learning simulÃ©e

---

## Ã€ propos

Projet rÃ©alisÃ© par **Rick Georges YELEUMEU**   


---

## Structure du dÃ©pÃ´t

```bash
projet_datalake_api/
â”œâ”€â”€ data_lake_api/          # Projet Django complet
â”œâ”€â”€ app.py                  # Application Streamlit de test
â”œâ”€â”€ requirements.txt        # DÃ©pendances
â”œâ”€â”€ architecture.png        # Diagramme dâ€™architecture
â”œâ”€â”€ README.md               # Ce fichier
```

---

## Remarques

- Lâ€™ensemble fonctionne en local sans besoin de dÃ©ploiement cloud
- Peut Ãªtre portÃ© facilement vers PostgreSQL + Docker pour industrialisation
- Toutes les fonctions sont testables via Swagger ou Streamlit

Bonne exploration
